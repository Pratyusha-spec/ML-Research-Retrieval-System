{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f63290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba49695c-1354-4af3-a7a1-5ad02d8e5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# from unsloth import FastLanguageModel\n",
    "# import torch\n",
    "# import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5421f160-1fe1-4179-b987-1b91f4157726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded70b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b82d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow==2.11.0 keras==2.11.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6546606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623d638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install simplet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f52c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0979afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pytorch-lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6059fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install simplet5 transformers pytorch-lightning torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09fadd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('archive.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "438af99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "2610990it [00:38, 67078.73it/s] \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from simplet5 import SimpleT5\n",
    "import pickle\n",
    "\n",
    "# Path to the dataset\n",
    "data_file = \"C:/Users/Keerthana/Documents/machine_learning/ML_Project/Project_Code/data/arxiv-metadata-oai-snapshot.json\"\n",
    "\n",
    "# Categories of interest\n",
    "paper_categories = [\"cs.AI\", \"cs.CV\", \"cs.LG\"]\n",
    "\n",
    "# Load dataset\n",
    "def get_metadata():\n",
    "    with open(data_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            yield line\n",
    "\n",
    "# Build dataset with more fields\n",
    "def build_dataset(categories=paper_categories):\n",
    "    data = []\n",
    "    metadata = get_metadata()\n",
    "    for paper in tqdm(metadata):\n",
    "        paper_dict = json.loads(paper)\n",
    "        category = paper_dict.get(\"categories\")\n",
    "        if category in categories:\n",
    "            try:\n",
    "                paper_info = {\n",
    "                    \"id\": paper_dict.get(\"id\"),\n",
    "                    \"submitter\": paper_dict.get(\"submitter\"),\n",
    "                    \"authors\": paper_dict.get(\"authors\"),\n",
    "                    \"title\": re.sub(r\"\\s+\", \" \", paper_dict.get(\"title\").replace(\"\\n\", \" \")),\n",
    "                    \"comments\": paper_dict.get(\"comments\"),\n",
    "                    \"journal_ref\": paper_dict.get(\"journal-ref\"),\n",
    "                    \"doi\": paper_dict.get(\"doi\"),\n",
    "                    \"report_no\": paper_dict.get(\"report-no\"),\n",
    "                    \"categories\": paper_dict.get(\"categories\"),\n",
    "                    \"license\": paper_dict.get(\"license\"),\n",
    "                    \"abstract\": re.sub(r\"\\s+\", \" \", paper_dict.get(\"abstract\").replace(\"\\n\", \" \")) if paper_dict.get(\"abstract\") else None\n",
    "                }\n",
    "                data.append(paper_info)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing paper: {e}\")\n",
    "                continue\n",
    "    papers = pd.DataFrame(data)\n",
    "    return papers\n",
    "\n",
    "# Generate DataFrame\n",
    "papers = build_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b102b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "076cc5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {\n",
    "    \"cs.AI\": \"Artificial Intelligence\",\n",
    "    \"cs.CV\": \"Computer Vision\",\n",
    "    \"cs.LG\": \"Machine Learning\",\n",
    "    # Add more categories as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79d2715d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal_ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report_no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cat_text</th>\n",
       "      <th>prepared_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.1267</td>\n",
       "      <td>Laurence Likforman</td>\n",
       "      <td>Laurence Likforman-Sulem, Abderrazak Zahour, B...</td>\n",
       "      <td>Text Line Segmentation of Historical Documents...</td>\n",
       "      <td>25 pages, submitted version, To appear in Inte...</td>\n",
       "      <td>Vol. 9, no 2-4, April 2007, pp. 123-138</td>\n",
       "      <td>10.1007/s10032-006-0023-z</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>None</td>\n",
       "      <td>There is a huge amount of historical documents...</td>\n",
       "      <td>Computer Vision</td>\n",
       "      <td>Text Line Segmentation of Historical Documents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.1274</td>\n",
       "      <td>Dev Rajnarayan</td>\n",
       "      <td>David H. Wolpert and Dev G. Rajnarayan</td>\n",
       "      <td>Parametric Learning and Monte Carlo Optimization</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>None</td>\n",
       "      <td>This paper uncovers and explores the close rel...</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Parametric Learning and Monte Carlo Optimizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.1394</td>\n",
       "      <td>Tarik Had\\v{z}i\\'c</td>\n",
       "      <td>Tarik Hadzic, Rune Moller Jensen, Henrik Reif ...</td>\n",
       "      <td>Calculating Valid Domains for BDD-Based Intera...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>In these notes we formally describe the functi...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Calculating Valid Domains for BDD-Based Intera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.2010</td>\n",
       "      <td>Juliana Bernardes</td>\n",
       "      <td>Juliana S Bernardes, Alberto Davila, Vitor San...</td>\n",
       "      <td>A study of structural properties on profiles HMMs</td>\n",
       "      <td>6 pages, 7 figures</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>Motivation: Profile hidden Markov Models (pHMM...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>A study of structural properties on profiles H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.2668</td>\n",
       "      <td>Alex Smola J</td>\n",
       "      <td>Le Song, Alex Smola, Arthur Gretton, Karsten B...</td>\n",
       "      <td>Supervised Feature Selection via Dependence Es...</td>\n",
       "      <td>9 pages</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>None</td>\n",
       "      <td>We introduce a framework for filtering feature...</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Supervised Feature Selection via Dependence Es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           submitter  \\\n",
       "0  0704.1267  Laurence Likforman   \n",
       "1  0704.1274      Dev Rajnarayan   \n",
       "2  0704.1394  Tarik Had\\v{z}i\\'c   \n",
       "3  0704.2010   Juliana Bernardes   \n",
       "4  0704.2668        Alex Smola J   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Laurence Likforman-Sulem, Abderrazak Zahour, B...   \n",
       "1             David H. Wolpert and Dev G. Rajnarayan   \n",
       "2  Tarik Hadzic, Rune Moller Jensen, Henrik Reif ...   \n",
       "3  Juliana S Bernardes, Alberto Davila, Vitor San...   \n",
       "4  Le Song, Alex Smola, Arthur Gretton, Karsten B...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Text Line Segmentation of Historical Documents...   \n",
       "1   Parametric Learning and Monte Carlo Optimization   \n",
       "2  Calculating Valid Domains for BDD-Based Intera...   \n",
       "3  A study of structural properties on profiles HMMs   \n",
       "4  Supervised Feature Selection via Dependence Es...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  25 pages, submitted version, To appear in Inte...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                 6 pages, 7 figures   \n",
       "4                                            9 pages   \n",
       "\n",
       "                               journal_ref                        doi  \\\n",
       "0  Vol. 9, no 2-4, April 2007, pp. 123-138  10.1007/s10032-006-0023-z   \n",
       "1                                     None                       None   \n",
       "2                                     None                       None   \n",
       "3                                     None                       None   \n",
       "4                                     None                       None   \n",
       "\n",
       "  report_no categories                                            license  \\\n",
       "0      None      cs.CV                                               None   \n",
       "1      None      cs.LG                                               None   \n",
       "2      None      cs.AI                                               None   \n",
       "3      None      cs.AI  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "4      None      cs.LG                                               None   \n",
       "\n",
       "                                            abstract                 cat_text  \\\n",
       "0  There is a huge amount of historical documents...          Computer Vision   \n",
       "1  This paper uncovers and explores the close rel...         Machine Learning   \n",
       "2  In these notes we formally describe the functi...  Artificial Intelligence   \n",
       "3  Motivation: Profile hidden Markov Models (pHMM...  Artificial Intelligence   \n",
       "4  We introduce a framework for filtering feature...         Machine Learning   \n",
       "\n",
       "                                       prepared_text  \n",
       "0  Text Line Segmentation of Historical Documents...  \n",
       "1  Parametric Learning and Monte Carlo Optimizati...  \n",
       "2  Calculating Valid Domains for BDD-Based Intera...  \n",
       "3  A study of structural properties on profiles H...  \n",
       "4  Supervised Feature Selection via Dependence Es...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cat_text(x):\n",
    "    \n",
    "    cat_text = ''\n",
    "    \n",
    "    # Put the codes into a list\n",
    "    cat_list = x.split(' ')\n",
    "    \n",
    "    for i, item in enumerate(cat_list):\n",
    "        \n",
    "        cat_name = category_map[item]\n",
    "        \n",
    "        # If there was no description available\n",
    "        # for the category code then don't include it in the text.\n",
    "        if cat_name != 'Not available':\n",
    "            \n",
    "            if i == 0:\n",
    "                cat_text = cat_name\n",
    "            else:\n",
    "                cat_text = cat_text + ', ' + cat_name\n",
    " \n",
    "    # Remove leading and trailing spaces\n",
    "    cat_text = cat_text.strip()\n",
    "    \n",
    "    return cat_text\n",
    "    \n",
    "\n",
    "papers['cat_text'] = papers['categories'].apply(get_cat_text)\n",
    "\n",
    "def clean_text(x):\n",
    "    \n",
    "    # Replace newline characters with a space\n",
    "    new_text = x.replace(\"\\n\", \" \")\n",
    "    # Remove leading and trailing spaces\n",
    "    new_text = new_text.strip()\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "papers['title'] = papers['title'].apply(clean_text)\n",
    "papers['abstract'] = papers['abstract'].apply(clean_text)\n",
    "\n",
    "papers['prepared_text'] = papers['title'] + ' \\n ' + papers['abstract']\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12137d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a212871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import Document\n",
    "\n",
    "# arxiv_documents = [Document(text=item) for item in list(papers['prepared_text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71ee07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q llama-index-embeddings-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90a252c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9661f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q llama-index-llms-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1ef5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q transformers torch tqdm pandas numpy llama-index chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "009179e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q llama-index llama-index-embeddings-huggingface llama-index-vector-stores-chroma llama-index-llms-huggingface chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47e81893-95ca-40f6-8a60-9cf537083769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39e2d8df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\unsloth\\__init__.py:87\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Torch 2.5 has including_emulation\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m major_version, minor_version \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_capability\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m SUPPORTS_BFLOAT16 \u001b[38;5;241m=\u001b[39m (major_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (major_torch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (minor_torch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m): \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\cuda\\__init__.py:509\u001b[0m, in \u001b[0;36mget_device_capability\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_capability\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the cuda capability of a device.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m        tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 509\u001b[0m     prop \u001b[38;5;241m=\u001b[39m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prop\u001b[38;5;241m.\u001b[39mmajor, prop\u001b[38;5;241m.\u001b[39mminor\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\cuda\\__init__.py:523\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import chromadb\n",
    "\n",
    "\n",
    "# Set up the embedding model using HuggingFace Transformers\n",
    "device_type = torch.device(\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-small-en-v1.5\")\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-small-en-v1.5\").to(device_type)\n",
    "\n",
    "def embed_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: val.to(device_type) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the mean pooling of the last hidden state for embeddings\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "# Create a persistent vector store\n",
    "chroma_client = chromadb.PersistentClient(path=\"./DB\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"academic_research\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Example documents (replace `arxiv_documents` with actual documents)\n",
    "arxiv_documents = [\n",
    "    {\"text\": \"Example paper on diffusion models for video generation.\"},\n",
    "    {\"text\": \"Another paper discussing GANs for video synthesis.\"}\n",
    "]\n",
    "\n",
    "# Embed documents and add them to the vector store\n",
    "for doc in arxiv_documents:\n",
    "    embedding = embed_text(doc[\"text\"])\n",
    "    chroma_collection.add(documents=[doc[\"text\"]], embeddings=[embedding])\n",
    "\n",
    "# Load the vector store and index\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_context)\n",
    "\n",
    "# Set up retrieval engine\n",
    "query_engine = index.as_retriever(similarity_top_k=5, alpha=0.5)  # Adjust alpha as needed\n",
    "\n",
    "# Add LLM evaluation for reranking using SentenceTransformer\n",
    "rerank_postprocessor = SentenceTransformerRerank(\n",
    "    model='mixedbread-ai/mxbai-rerank-xsmall-v1',\n",
    "    top_n=2,  # Limit the number of reranked results\n",
    "    keep_retrieval_score=True\n",
    ")\n",
    "\n",
    "# Optional: Use ColBERT for fine-grained contextual reranking\n",
    "colbert_reranker = ColbertRerank(\n",
    "    top_n=2,\n",
    "    model=\"colbert-ir/colbertv2.0\",\n",
    "    tokenizer=\"colbert-ir/colbertv2.0\",\n",
    "    keep_retrieval_score=True,\n",
    ")\n",
    "\n",
    "# Define query engine with rerankers\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    node_postprocessors=[rerank_postprocessor, colbert_reranker],\n",
    ")\n",
    "\n",
    "# Load LLM for response generation\n",
    "max_seq_length = 1024\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/gemma-7b-bnb-4bit\", \n",
    "    max_seq_length=max_seq_length, \n",
    "    load_in_4bit=True, \n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "llm = HuggingFaceLLM(model=model, tokenizer=tokenizer, context_window=4096, max_new_tokens=max_seq_length)\n",
    "\n",
    "# Customize prompts\n",
    "system_prompt = \"\"\"\n",
    "You are an expert academic assistant specializing in retrieving and summarizing research papers.\n",
    "Always provide direct and concise answers to queries using only the provided context.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\" \n",
    "Context information is below.\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context, answer the query:\n",
    "Query: {query_str}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "refine_prompt = \"\"\"\n",
    "Original query: {query_str}\n",
    "Existing answer: {existing_answer}\n",
    "Additional context:\n",
    "---------------------\n",
    "{context_msg}\n",
    "---------------------\n",
    "Refine the existing answer or return the original if no refinement is needed.\n",
    "Refined Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Integrate prompts into the query engine\n",
    "from llama_index.core import ChatPromptTemplate, PromptTemplate\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "prompt_template = PromptTemplate(user_prompt)\n",
    "refine_template = PromptTemplate(refine_prompt)\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similarity_top_k=5,\n",
    "    node_postprocessors=[rerank_postprocessor, colbert_reranker],\n",
    ")\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": prompt_template, \"response_synthesizer:refine_template\": refine_template}\n",
    ")\n",
    "\n",
    "# Example Query Execution\n",
    "response = query_engine.query(\"What are some papers about video generation using diffusion models?\")\n",
    "print(response.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02366ee2-7185-430c-919f-bd017377c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install unsloth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow==2.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow==2.11.0 keras==2.11.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pip setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2dc90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow==2.11 keras==2.11 transformers==4.35.0 sentence-transformers llama-index chromadb torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ed40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers==4.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26190f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5702514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import Document, VectorStoreIndex, Settings\n",
    "# from llama_index.embeddings import HuggingFaceEmbedding\n",
    "# from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "# from llama_index.core import StorageContext\n",
    "# from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "# from llama_index.postprocessor.colbert_rerank import ColbertRerank\n",
    "# from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "# from unsloth import FastLanguageModel\n",
    "# import torch\n",
    "# import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fbc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import llama_index.embeddings\n",
    "# print(dir(llama_index.embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250739c4-5e45-4875-b45d-4d917156ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8609c8d-699b-403c-b21d-afd6c19ceda2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_env)",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
